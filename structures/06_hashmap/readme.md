# Hash map
## 705_Design_HashSet
使用$hash\_key = key \% size$作为哈希函数，以链表作为容器。
使用质数作为 size 是一个明智的选择。例如769，可以减少潜在的碰撞。
K为桶数量，N为插入的元素数量。
时间复杂度:$O(N/K)$。
* 假设值是平均分布的，因此可以考虑桶的平均大小是$N/K$
* 对于每个操作，在最坏的情况下，我们需要扫描整个桶。

空间复杂度：O(K+N)。

单个容器中的元素较多时，还可以使用二叉搜索树作为容器。时间复杂度可以降为$O(log(N/K))$。

## 706_Design_HashMap
和设计set一样，不过储存的对象是```pair(key, value)```。
注意可以通过指针运算符(->)来操作迭代器，改变value的值。
时间复杂度:$O(N/K)$。
* 假设值是平均分布的，因此可以考虑桶的平均大小是$N/K$
* 对于每个操作，在最坏的情况下，我们需要扫描整个桶。

空间复杂度：O(K+N)。

## 136_Single_Number_01 哈希映射
除了一个元素出现一次，其他的都出现两次。那么如果第一次存入set，第二次删除它，最终set中的那个元素就是只出现了一次的元素。
时间复杂度：O(n)。遍历数组，每次查找、添加或者删除的复杂度为O(1)，总共是O(n)。
空间复杂度：最好O(1)，相同的元素挨在一起；最坏O((n-1)/2))，不同的元素挨在一起。

## 136_Single_Number_02 异或算法
上一题的空间复杂度不满足要求。这里很巧妙的使用了异或的几个特性：
$$a \oplus b = b \oplus a \\ a \oplus a = 0 \\a \oplus 0 = a$$
所以我们遍历数组，做异或运算，相同的两个数字异或会抵消为0，最终结果就是只出现一次的数字。
时间复杂度:O(n)。
空间复杂度:O(1)。

## 349_Intersection_of_Two_Arrays
此题的思想和二分查找一样：遍历一个数组，在另外一个里面找。查找这个操作如果我们也用遍历，那复杂度相当高。所以二分查找将查找的复杂度降到了O(logn)，而unordered_set的查找复杂度为O(1)。
时间复杂度：O(m+n)。遍历构造unordered_set，和遍历查找。
空间复杂度：O(m)。m是unordered_set的大小。

## 202_Happy_Number_01 set判断循环
对于一个数，不断地进行快乐操作，会有两种情况：
1.最终收敛到1；
2.最终进入循环；
它会不会越来越大呢？肯定不会。因为每位的平方相加收敛会很快，比如9999，下一步就是324。

所以我们有两个判断条件，到达1或者进入循环。后者我们用一个set来判断。

时间复杂度：$O(243 \cdot 3 + \log n + \log\log n + \log\log\log n +...) = O(logn)$。
* 查找给定数字的下一个值的成本为$O(log_{10}n)$，因为我们正在处理数字中的每位数字，而数字中的位数由$O(log_{10}n)$给定。

* 我们在上面确定，一旦一个数字低于 243，它就不可能回到 243 以上。对于高于 243 的 n，我们需要考虑循环中每个数高于 243 的成本。通过数学运算，我们可以证明在最坏的情况下，这些成本将是$O(243 \cdot 3 + \log n + \log\log n + \log\log\log n +...)$..。
O(logn) 是占主导地位的部分，而其他部分相比之下都很小，所以我们忽略它们。

空间复杂度：O(logn)。但是可以优化到O(1)，因为总是在243下进入循环，我们可以只在set中插入243以下的元素。

## 202_Happy_Number_02 快慢指针
这里就很明显了——涉及到环的问题，考虑一下快慢指针总是没错的。
如果是快乐数，fast会先到1；否则两者在环上某处相遇。

时间复杂度：O(logn)。
空间复杂度：O(1)。

## 205_Isomorphic_Strings_01 map+set
用map来保存映射，set来记录哪些char已经被映射了。
我们遍历s，如果s[i]不存在于map中，此时对应位置的t[i]有两种情况：
* 1.没有被映射过，我们把它加入set，把(s[i], t[i])加入map；
* 2.已经被映射过，那么s[i]这个key不存在，说明t[i]已经被另一个映射了。这说明有两个不同的s[m]和s[n]，映射到了同一个t[m]，那么返回false。

如果s[i]在map中，我们则判断当前对应的t[i]是否等于map[s[i]]，也就是验证之前的映射和当前的字母是否相同。

时间复杂度：O(n)
空间复杂度：O(2n) = O(n)

## 205_Isomorphic_Strings_02 map双向验证
上一个办法，我们是用set来检查，是否有一个t[i]被映射了两次。如果不用set，只能保证s->t有效。那么其实只需要把s、t交换并再验证一次，就能验证t->s是否有效了。

时间复杂度：O(2n) = O(n)
空间复杂度：O(n) 

## 205_Isomorphic_Strings_03 第三方映射
paper -> 12134
title -> 12134
两者同构

foo -> 122
bar -> 123
两者不同构

显然，我们把它映射到数字之后，就能很方便地对比两者是否同构。
可以发现，可以把每个字母对应的数字，指定为它第一次出现的位置下标。比如：
paper -> 12145
title -> 12145
两者同构

那么就遍历比较s和t中字符第一次出现的位置是否相等就可以了。
时间复杂度：O(n)
空间复杂度：O(1) 

## 599_Minimum_Index_Sum_of_Two_Lists
把list1中的str和下标存入map，遍历list2，去map中查找。
这里需要记录下下标和，如果比当前的小，那么就舍弃之前所有的，保存当前的；如果相等，则直接存入；比当前的大，那么直接舍弃。
将index_sum初始化为```list1.size() + list2.size()```，保证第一对能存进去。

时间复杂度：O(m+n)。分别是两表的长度。
空间复杂度：O(m*len)。len是list1中字符串的平均长度。

## 387_First_Unique_Character_in_a_String
第一次遍历统计次数，第二次遍历找第一个只出现一次的。
时间复杂度：O(n)
空间复杂度：O(n) 

## 350_Intersection_of_Two_Arrays_II
遍历较小的数组，统计每个数字出现的次数。
遍历另一个数组，在map当中查找：
如果出现的次数大于1,那么将此数存入结果，并且将次数减一。

时间复杂度：O(m+n)。分别是两数组的长度。
空间复杂度：O(m)。m是较短的数组的长度。

## 219_Contains_Duplicate_II_01 unordered_multimap
这个其实运用了unordered_multimap的一个特性:**虽然它是无序的，但是相同的key还是被放在一个桶里。所以我们可以使用迭代器递增，来访问所有具有相同key的元素。**

我们遍历数组存进map，第二次遍历去寻找有相同值的元素，并逐个比较下标是否满足要求。
时间复杂度:O(2n) = O(n)
空间复杂度：O(n)

## 219_Contains_Duplicate_II_02 unordered_set + 滑动窗口
我们需要一个支持在常量时间内完成 搜索，删除，插入 操作的数据结构，那就是散列表。
遍历数组，对于每个元素做以下操作：
* 在散列表中搜索当前元素，如果找到了就返回 true。
（**注意！这里的搜索，需要用set.find()而不是std::find()。后者会排序后再查找，复杂度很高。）**
* 在散列表中插入当前元素。
* 如果当前散列表的大小超过了k， 删除散列表中最旧的元素。
* 返回 false。

时间复杂度：O(n)
空间复杂度：O(min(n,k))

**注意，这里如果选择set，即使用二叉搜索树来查找窗口内的数字，虽然比线性搜索好，但搜索、插入复杂度也是O(logn)，远不如散列表的O(1)，这也是使用散列表的原因。**

## 49_Group_Anagrams_01 multimap + <string， string>键值对
这道题的思路就是，字母异位词具有相同的排序结果。所以我们将其排序后的结果作为key，其本身作为value，最后用迭代器按key取出value。
时间复杂度：O(n)
空间复杂度:O(n)

## 49_Group_Anagrams_02 map + <string, vector<string>>键值对
此题我本来是<string， string>键值对，最后用迭代器去取值存入vector。其实完全可以用<string, vector<string>>键值对，直接访问key就可以了。很有启发性的用法。
时间复杂度：O(n)
空间复杂度:O(n)

## 36_Valid_Sudoku
这道题就很典型了。
1.用途典型：使用map来判断是否有重复。
2.方法典型：在插入的时候判断是否已经存在。
3.设计典型：我们要的是不是某个位置的整体坐标，也不是它的值，而是它所在的row、col、box。**需要判断什么重复，什么就作为键。**

这里一开始的想法很直接，遍历三次，分别判断row、col、box有无重复。但这样显然时间复杂度太高。
思考：每次遍历到一个元素，我们要判断其所在行、所在列，所在box有无这个元素存在；显然，我们根据其坐标，可以立即知道其所在行、所在列，所在box。所以只需要遍历一次，每次在三个map中进行查询，无则添加，有则判断有重复。

时间复杂度：O(1)；
空间复杂度：O(1)；（这里理解为，规模已经给定不会增长，所以是常量空间）。

## 652_Find_Duplicate_Subtrees
此题和上一题的核心思路一样：**需要判断什么重复，什么就作为键。**
所以这里我们要判断某节点子树的结构是否已经存在，那么其子树的结构就是key。显然，我们不可能真正把子树存进map，所以我们需要一个值来代表其子树结构，那就是对子树进行序列化。

使用一个```_getkey()```函数，来对结点和子树进行序列化。显然，因为root的子树序列，是其左右子树的序列的拼接，这是一个递归的过程。

所以，我们在回溯的过程中，就可以进行判断了：在map中进行查询，无则添加序列作为key，有则判断有重复，保存下node。

不需要回溯上来之后，又从上到下去逐一判断，这样每次```_getkey()```都会访问其子树节点，复杂度太高。

时间复杂度：主要是受字符串拼接影响，假设 root.val 的长度为 a，root.left 的长度为 b，root.right 的长度为 c，每次字符串拼接所需时间是 a + b + c <= N，而一共有 N 个节点，所以是 O(N^2)。

空间复杂度：O(N^2)。主要是 Map 的 key 占的空间。


## 3_Longest_Substring_Without_Repeating_Characters
这道题本来我的想法是，遍历字符串，不重复则存入map，++len；遇到重复的，就清空map，len归0，从重复的下一位开始重新开始这个过程。

这样有个问题：map的清空和再插入需要大量时间，最坏的情况要重新遍历字符串。
我们注意到，当出现重复，重复的下一位到当前位之间，是没有重复的，所以我们只需要多维护一个起点，将起点移到重复的下一位，继续遍历，并且在遇到起点之前的字符时，不判断重复，而是当成新字符重新覆盖写入。**当前情况不符合要求时，要判断哪些资源是还有效的。而不是一味地全部舍弃重新来。**

时间复杂度：O(n)。遍历数组，每次的插入和查找都是O(1)。
空间复杂度：O(n)。最坏需要存入整个字符串。

## 454_4Sum_II
思路其实很简单：
* 1.遍历组合k个数组，每次每个数组分别取一个数，相加得到sum，存入map，记录该sum出现的次数；

* 2.遍历剩下的4-k个数组，每次每个数组分别取一个数，其和为sum。如果在map里存在-sum，则count加上map[-sum]。

需要考虑的是：如果k=1，如在 ABC 里组合，去D中寻找。这样的时间复杂度为O(n) + O(n^3) = O(n^3)；
如果k=2，如在 AB 里组合，去CD中寻找。这样的时间复杂度为O(n^2) + O(n^2) = O(n^2)。

时间复杂度：O(n^2)
空间复杂度：O(n)

## 347_Top_K_Frequent_Elements_01 unordered_map + multimap
这里用一个hash_map来统计出现次数是显然的，问题是在于怎么去找出前K大的次数。

容易想到通过对出现次数从大到小排序，取前K个元素。但是快排的时间复杂度是O(nlogn)，不符合要求。

所以我们肯定不能直接排序。如果使用tree_map来保证有序呢？
multimap里，插入、查找和删除的时间复杂度都是O(logn)，如果我们保存全部n个元素，也不符合要求。
我们既然只需要前k大的元素，那就只需要维护一个具有K个节点的BST。当树满了之后，有新的数据进来，如果它大于树中最小的元素，那么用它代替这个元素。这样总的时间复杂度就是O(nlogk)< O(nlogn)，符合题意。

时间复杂度：O(n)+O(nlogk)=O(nlogk)
空间复杂度：O(n)

## 347_Top_K_Frequent_Elements_02 桶排序
刚刚我们提到，排序之所以不行，是因为复杂度太高。但是我们知道，桶排序的时间复杂度为O(n)，所以如果可以应用桶排序，也是符合要求的。

我们统计完次数之后，对每个桶编号，把出现次数为x的元素放到编号为x的桶里。最后，我们只需要依顺序从桶中取出k个元素即可。

时间复杂度：O(n)。我们一次遍历数组统计次数，一次遍历map存入桶中，桶中并不需要排序。最终取出元素是O(k)=O(1)。

空间复杂度：O(n)。

## 380_Insert_Delete_GetRandom_O(1)
此题经典经典之再经典。经典在于，如何通过分析需求，选择符合要求的数据结构，并且进行实现。
需求如下：
**在平均复杂度为O(1)的条件下实现以下操作：**
* 1.```insert```
* 2.```remove```
* 3.```getRadom```

分析：
1.对于```insert```和```remove```：我们知道散列表和链表可以O(1)时间内插入、删除。

2.对于```getRadom```，由于散列表和链表都没有索引，所以无法在O(1)时间内，随机地访问元素。只有数组可以在O(1)随机地访问元素。

所以，我们一定是用数组来保存元素。但是数组对元素的插入、删除都是线性时间，与操作位置后面的元素个数有关。
那么答案出现了，我们每次插入都在最后插入，删除都把目标元素与最后一个元素交换，然后在最后删除。
由于每次删除，我们需要在O(1)内得到目标元素的索引，所以每次插入时，我们用一个map记录元素和它对应的索引。

以上，就是一个完整的，由需求分析得到解决方案的过程。
之前自己的想法，是用```vector<list<int>>```。
这样在较平衡的情况下，勉强能做到O(1)的```insert```和```remove```。但是无法实现O(1)的```getRandom```。

时间复杂度：
```getRandom``` 时间复杂度为O(1)；
```insert```和```remove```平均时间复杂度为O(1)，在最坏情况下为O(N)（当元素数量超过当前分配的动态数组和哈希表的容量导致扩容时。）

空间复杂度：O(n)